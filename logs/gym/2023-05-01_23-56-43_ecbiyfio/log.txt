__name__: __main__
__doc__: None
__package__: None
__loader__: <_frozen_importlib_external.SourceFileLoader object at 0x7f000cae64c0>
__spec__: None
__annotations__: {}
__builtins__: <module 'builtins' (built-in)>
__file__: /home/vlaffo/Desktop/ge_q_dts/simple_test_orthogonal.py
__cached__: None
os: <module 'os' from '/usr/lib/python3.8/os.py'>
randrange: <bound method Random.randrange of <random.Random object at 0x21c7e20>>
gym: <module 'gym' from '/home/vlaffo/Desktop/ge_q_dts/venv/lib/python3.8/site-packages/gym/__init__.py'>
json: <module 'json' from '/usr/lib/python3.8/json/__init__.py'>
string: <module 'string' from '/usr/lib/python3.8/string.py'>
datetime: <module 'datetime' from '/usr/lib/python3.8/datetime.py'>
argparse: <module 'argparse' from '/usr/lib/python3.8/argparse.py'>
subprocess: <module 'subprocess' from '/usr/lib/python3.8/subprocess.py'>
np: <module 'numpy' from '/home/vlaffo/Desktop/ge_q_dts/venv/lib/python3.8/site-packages/numpy/__init__.py'>
time: <built-in function time>
sleep: <built-in function sleep>
random: <module 'numpy.random' from '/home/vlaffo/Desktop/ge_q_dts/venv/lib/python3.8/site-packages/numpy/random/__init__.py'>
EpsGreedyLeaf: <class 'dt.decision_tree.EpsGreedyLeaf'>
PythonDT: <class 'dt.python_decision_tree.PythonDT'>
RandomlyInitializedEpsGreedyLeaf: <class 'dt.decision_tree.RandomlyInitializedEpsGreedyLeaf'>
GrammaticalEvolutionTranslator: <class 'grammatical_evolution.GrammaticalEvolutionTranslator'>
grammatical_evolution: <function grammatical_evolution at 0x7efff17769d0>
differential_evolution: <function differential_evolution at 0x7efff1776b80>
string_to_dict: <function string_to_dict at 0x7f000c8e7820>
parser: ArgumentParser(prog='simple_test_orthogonal.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)
date: 2023-05-01_23-56-43
logdir: logs/gym/2023-05-01_23-56-43_ecbiyfio
logfile: logs/gym/2023-05-01_23-56-43_ecbiyfio/log.txt
args: Namespace(crossover={'function': 'tools.cxOnePoint'}, cxp=0.5, df=0.9, environment_name='gym_examples:gym_examples/GridWorld-v0', episode_len=100, episodes=50, eps=0.05, generations=200, genotype_len=100, input_space=3, jobs=1, lambda_=50, learning_rate='auto', low=-10, mp=0.5, mutation={'function': 'tools.mutUniformInt', 'low': 0, 'up': 40000, 'indpb': 0.1}, n_actions=6, seed=5, selection={'function': 'tools.selTournament', 'tournsize': 2}, types='#0,5,1,1;0,5,1,1;0,5,1,1', up=10)
best: None
input_space_size: 3
lr: auto
CLeaf: <class '__main__.CLeaf'>
grammar: {'bt': ['<if>'], 'if': ['if <condition>:{<action>}else:{<action>}'], 'condition': ['_in_0<comp_op><const_type_0>', '_in_1<comp_op><const_type_1>', '_in_2<comp_op><const_type_2>'], 'action': ['out=_leaf;leaf="_leaf"', '<if>'], 'comp_op': [' < ', ' > '], 'const_type_0': ['0.0', '1.0', '2.0', '3.0', '4.0'], 'const_type_1': ['0.0', '1.0', '2.0', '3.0', '4.0'], 'const_type_2': ['0.0', '1.0', '2.0', '3.0', '4.0']}
types: 0,5,1,1;0,5,1,1;0,5,1,1
index: 2
type_: 0,5,1,1
rng: ['0', '5', '1', '1']
start: 0
stop: 5
step: 1
divisor: 1
consts_: ['0.0', '1.0', '2.0', '3.0', '4.0']
f: <_io.TextIOWrapper name='logs/gym/2023-05-01_23-56-43_ecbiyfio/log.txt' mode='a' encoding='UTF-8'>
[2023-05-01 23:56:51.418200] New best at generation 0 with fitness (0.0,)
[16740, 23496, 34736, 1900, 30515, 16321, 3398, 10279, 7419, 24365, 30740, 16159, 24953, 35635, 6682, 37613, 16340, 859, 14203, 26748, 18316, 11932, 25522, 10459, 4714, 9094, 29152, 8303, 8666, 116, 348, 13726, 14121, 10869, 10910, 18959, 20555, 13034, 35338, 13420, 11905, 12902, 25114, 19581, 1413, 23670, 27191, 10876, 9548, 17289, 4268, 21748, 19749, 39525, 38413, 221, 39058, 22144, 4326, 20313, 23288, 20058, 31506, 20695, 12109, 31537, 30968, 11542, 3735, 16789, 1498, 23438, 26495, 1184, 35983, 27448, 23998, 24665, 37913, 594, 29676, 3062, 11856, 12879, 7800, 16127, 30291, 22569, 33586, 23251, 34386, 16442, 30333, 7081, 38650, 24071, 19389, 2400, 28375, 5975]
Leaves
{'leaf_0': -5.56, 7.41, -5.87, 8.37, -0.23, 2.23, 'leaf_1': 5.32, 0.37, -4.06, -6.25, -8.39, 4.77, 'leaf_2': -1.17, -6.83, 7.60, -4.52, -1.72, -4.08, 'leaf_3': 2.58, 1.60, 2.00, -4.68, -4.31, -4.93, 'leaf_4': -3.45, -7.12, -6.69, 9.28, 9.20, -6.23, 'leaf_5': 2.25, 2.32, 2.51, 2.51, 2.12, 2.47}
[2023-05-01 23:56:51.418359] New best at generation 0 with fitness (0.04,)
[28222, 17741, 411, 30272, 3988, 29690, 26880, 11125, 2945, 2180, 35941, 34009, 37040, 22938, 6148, 4667, 15531, 32188, 6025, 30884, 3523, 15955, 3306, 32598, 26038, 3941, 3139, 16739, 26704, 29220, 20050, 3364, 2464, 12746, 11756, 33333, 26368, 12324, 34819, 15317, 5528, 20570, 7076, 5689, 35516, 10612, 39209, 4939, 14051, 1140, 28915, 35365, 23436, 31885, 27733, 37448, 24682, 34230, 8699, 809, 20159, 29428, 14678, 36337, 7581, 9090, 20428, 31668, 5743, 17267, 26384, 20504, 8694, 8507, 35177, 5372, 30907, 16046, 5526, 28092, 37813, 16081, 18076, 4026, 32286, 16303, 3147, 13097, 18744, 24494, 6457, 4710, 27562, 20573, 24894, 36443, 4, 18737, 8620, 37665]
Leaves
{'leaf_0': 3.36, 2.78, 3.36, 3.14, 3.30, 3.36, 'leaf_1': 3.01, 3.34, 2.99, 3.34, 3.35, 3.35}
[2023-05-01 23:57:08.532339] New best at generation 2 with fitness (0.06,)
[1211, 32363, 20818, 39250, 30023, 8934, 30681, 15502, 5063, 23909, 4995, 942, 12111, 28116, 5608, 17478, 8608, 24441, 21898, 14064, 9960, 19253, 33968, 36541, 5902, 18588, 10234, 27399, 26176, 24575, 19896, 24162, 31305, 14313, 29815, 29056, 15788, 37268, 9205, 17240, 1148, 35740, 827, 25248, 8755, 15566, 31532, 3663, 533, 997, 13849, 8255, 15951, 28117, 15468, 20101, 3673, 32803, 15631, 2509, 25263, 22659, 1402, 36553, 19512, 15414, 29492, 32521, 33467, 15291, 21537, 27154, 1393, 14166, 23842, 7880, 7, 20616, 7831, 9751, 15555, 20616, 18800, 35232, 5938, 16371, 14683, 6834, 36627, 31372, 16581, 7700, 34833, 34326, 17625, 2849, 272, 6895, 34961, 28791]
Leaves
{'leaf_0': 3.06, 3.21, 3.06, 3.00, 2.98, 3.06, 'leaf_1': 2.02, 3.66, 3.33, 3.13, 3.74, 3.73, 'leaf_2': -3.69, -9.54, -6.87, -5.80, 3.54, 6.05, 'leaf_3': -9.11, 3.91, 0.96, -6.08, -1.59, -3.40, 'leaf_4': -4.23, 6.67, -0.75, 5.56, -6.10, 6.69, 'leaf_5': -6.14, 7.00, 1.38, 4.89, 2.57, -9.79, 'leaf_6': 0.58, -5.22, 4.67, 6.46, 6.88, -3.53, 'leaf_7': -8.84, -0.88, 1.11, -8.37, -4.59, -9.80, 'leaf_8': -4.02, -7.43, -8.81, -5.39, -2.53, -6.40, 'leaf_9': -0.03, -6.50, 2.28, -8.76, -6.38, 5.35, 'leaf_10': 5.02, -7.26, -1.25, 8.62, 9.26, -1.92, 'leaf_11': -8.33, 0.56, -3.14, -9.13, -1.71, -2.65, 'leaf_12': 1.01, 6.00, 1.77, 4.17, 2.36, -4.03, 'leaf_13': 1.82, 9.03, -6.80, -1.17, 1.59, -3.61, 'leaf_14': 3.73, 2.62, 3.73, 3.43, 3.72, 2.03}
[2023-05-01 23:57:24.945094] New best at generation 4 with fitness (0.7,)
[1211, 17516, 20818, 39250, 34988, 8934, 30681, 15502, 5063, 29235, 2038, 942, 12111, 28116, 11034, 17478, 8608, 24441, 21898, 14064, 9960, 19253, 33968, 36541, 5902, 18588, 7273, 27399, 26176, 24575, 19896, 24162, 31305, 35885, 18926, 29056, 15788, 37268, 21864, 28560, 34845, 34066, 22267, 14680, 10735, 32344, 33572, 32342, 8979, 21182, 3217, 23387, 20889, 584, 32743, 2776, 13336, 12474, 35941, 16605, 18177, 19569, 22508, 15818, 29059, 26764, 37248, 32521, 31248, 15291, 21537, 27154, 16979, 14166, 23842, 28589, 7, 20616, 7831, 9751, 15555, 19304, 18800, 15393, 23217, 16371, 19220, 6834, 36627, 32992, 33837, 18188, 28715, 38221, 30397, 24712, 29768, 26654, 10161, 35516]
Leaves
{'leaf_0': 3.71, 3.71, 3.71, 3.17, 3.71, 3.54, 'leaf_1': 2.91, 2.93, -3.23, 2.93, -2.26, 2.63, 'leaf_2': 3.49, 3.49, 1.95, 2.48, 0.75, 2.30, 'leaf_3': 3.54, 6.05, -9.11, 3.91, 0.96, -6.08, 'leaf_4': -1.59, -3.40, -4.23, 6.67, -0.75, 5.56, 'leaf_5': -6.10, 6.69, -6.14, 7.00, 1.38, 4.89, 'leaf_6': 3.43, 2.25, 3.53, 3.72, 3.52, 3.53}
[2023-05-02 00:06:25.045357] New best at generation 69 with fitness (0.92,)
[1211, 17516, 14768, 39250, 34988, 8934, 30681, 15502, 5063, 2076, 2038, 942, 12111, 28116, 24814, 36884, 228, 24441, 21898, 5434, 12696, 19253, 33968, 36541, 5902, 18588, 7273, 27399, 26176, 24575, 19896, 24162, 31305, 35885, 18926, 29056, 1576, 37268, 13293, 28560, 39618, 31511, 22267, 14680, 38416, 32344, 33572, 32342, 9085, 21182, 3217, 23387, 20889, 584, 32743, 22172, 13336, 12474, 35941, 16605, 18177, 19569, 6737, 15818, 30714, 26764, 18480, 32521, 31248, 15291, 25786, 27154, 16979, 14166, 23842, 28589, 7, 20616, 7831, 9751, 15555, 19304, 18800, 15393, 23217, 16371, 19220, 6834, 33073, 32992, 33837, 29042, 28715, 38221, 30397, 24712, 29768, 26654, 10161, 31152]
Leaves
{'leaf_0': 2.07, -1.77, -0.84, -0.98, 4.12, -5.21, 'leaf_1': 9.26, -5.68, 9.65, -9.70, 0.96, 6.77, 'leaf_2': 2.09, 5.25, -2.98, 2.99, -3.28, 2.48, 'leaf_3': 6.67, -4.09, -1.74, 9.11, -4.34, 5.61, 'leaf_4': -0.74, 6.31, 3.84, 2.57, -7.24, 4.47, 'leaf_5': -8.22, 0.15, 8.92, 5.80, 3.26, -8.72, 'leaf_6': 5.98, 5.24, 5.97, 5.48, 5.92, 2.40}
[2023-05-02 00:13:56.514607] New best at generation 119 with fitness (1.0,)
[1211, 17516, 14768, 27778, 34988, 8934, 30681, 15502, 5063, 2511, 2038, 942, 12111, 28116, 24814, 36884, 228, 24441, 21898, 5434, 12696, 19253, 33968, 36541, 5902, 18588, 7273, 27399, 26176, 24575, 19896, 24162, 31305, 35885, 18926, 29056, 1576, 37268, 13293, 28560, 39618, 31511, 22267, 14680, 38416, 32344, 33572, 32342, 9085, 37759, 3217, 23387, 20889, 584, 32743, 16858, 13336, 12474, 35941, 16605, 26694, 33578, 10289, 15818, 29059, 26764, 37248, 32521, 31248, 15291, 21537, 27154, 16979, 14166, 23842, 28589, 7, 20616, 7831, 9751, 15555, 19304, 18800, 15393, 23217, 32911, 19220, 29323, 36627, 32992, 33837, 5726, 28715, 38221, 30397, 24712, 29768, 26654, 10161, 35516]
Leaves
{'leaf_0': 1.39, 0.15, 2.65, 0.22, 4.27, -6.60, 'leaf_1': 1.50, 6.58, -6.05, 9.49, -7.39, 8.71, 'leaf_2': -0.21, 6.13, 3.43, 1.71, 0.95, 4.00, 'leaf_3': -1.01, -4.14, -6.74, -7.77, 4.69, -0.20, 'leaf_4': -6.43, 9.24, -2.07, -1.81, 2.07, -7.25, 'leaf_5': -5.39, -0.98, 3.89, -5.21, 9.26, -5.68, 'leaf_6': 7.56, -9.70, 5.69, 5.89, -3.79, 4.13}
gen	nevals	avg     	std        	min  	max 
0  	50    	-339.996	473.712    	-1000	0.04
1  	39    	-59.9936	237.488    	-1000	0.04
2  	37    	0.012   	0.0164924  	0    	0.06
3  	39    	0.0168  	0.0184868  	0    	0.06
4  	38    	0.0376  	0.0963859  	0    	0.7 
5  	40    	0.0556  	0.132743   	0    	0.7 
6  	35    	0.0632  	0.130865   	0    	0.7 
7  	33    	0.0712  	0.130425   	0    	0.7 
8  	35    	0.1016  	0.178071   	0    	0.7 
9  	42    	0.1452  	0.215028   	0.02 	0.7 
10 	37    	0.1572  	0.214141   	0.02 	0.7 
11 	39    	0.2064  	0.244113   	0.04 	0.7 
12 	36    	0.2632  	0.258777   	0.04 	0.7 
13 	31    	0.3292  	0.278171   	0.04 	0.7 
14 	39    	0.3608  	0.268029   	0.04 	0.7 
15 	42    	0.4216  	0.251168   	0.06 	0.7 
16 	39    	0.5032  	0.240611   	0.06 	0.7 
17 	37    	0.5404  	0.231326   	0.06 	0.7 
18 	37    	0.5888  	0.19621    	0.06 	0.7 
19 	37    	0.6108  	0.183443   	0.06 	0.7 
20 	39    	0.6212  	0.173178   	0.06 	0.7 
21 	39    	0.624   	0.165312   	0.14 	0.7 
22 	36    	0.6548  	0.138032   	0.14 	0.7 
23 	34    	0.668   	0.110272   	0.18 	0.7 
24 	40    	0.6784  	0.0854953  	0.34 	0.7 
25 	36    	0.6928  	0.0504     	0.34 	0.7 
26 	29    	0.6928  	0.0504     	0.34 	0.7 
27 	40    	0.6928  	0.0504     	0.34 	0.7 
28 	36    	0.6928  	0.0504     	0.34 	0.7 
29 	39    	0.7     	2.22045e-16	0.7  	0.7 
30 	31    	0.7     	2.22045e-16	0.7  	0.7 
31 	35    	0.7     	2.22045e-16	0.7  	0.7 
32 	43    	0.7     	2.22045e-16	0.7  	0.7 
33 	37    	0.7     	2.22045e-16	0.7  	0.7 
34 	39    	0.7     	2.22045e-16	0.7  	0.7 
35 	37    	0.7     	2.22045e-16	0.7  	0.7 
36 	37    	0.7     	2.22045e-16	0.7  	0.7 
37 	37    	0.7     	2.22045e-16	0.7  	0.7 
38 	39    	0.7     	2.22045e-16	0.7  	0.7 
39 	44    	0.7     	2.22045e-16	0.7  	0.7 
40 	37    	0.7     	2.22045e-16	0.7  	0.7 
41 	38    	0.7     	2.22045e-16	0.7  	0.7 
42 	31    	0.7     	2.22045e-16	0.7  	0.7 
43 	32    	0.7     	2.22045e-16	0.7  	0.7 
44 	33    	0.7     	2.22045e-16	0.7  	0.7 
45 	37    	0.7     	2.22045e-16	0.7  	0.7 
46 	39    	0.7     	2.22045e-16	0.7  	0.7 
47 	44    	0.7     	2.22045e-16	0.7  	0.7 
48 	40    	0.7     	2.22045e-16	0.7  	0.7 
49 	42    	0.7     	2.22045e-16	0.7  	0.7 
50 	35    	0.7     	2.22045e-16	0.7  	0.7 
51 	38    	0.7     	2.22045e-16	0.7  	0.7 
52 	42    	0.7     	2.22045e-16	0.7  	0.7 
53 	31    	0.7     	2.22045e-16	0.7  	0.7 
54 	33    	0.7     	2.22045e-16	0.7  	0.7 
55 	44    	0.7     	2.22045e-16	0.7  	0.7 
56 	44    	0.7     	2.22045e-16	0.7  	0.7 
57 	37    	0.7     	2.22045e-16	0.7  	0.7 
58 	38    	0.7     	2.22045e-16	0.7  	0.7 
59 	37    	0.7     	2.22045e-16	0.7  	0.7 
60 	27    	0.7     	2.22045e-16	0.7  	0.7 
61 	38    	0.7     	2.22045e-16	0.7  	0.7 
62 	36    	0.7     	2.22045e-16	0.7  	0.7 
63 	30    	0.7     	2.22045e-16	0.7  	0.7 
64 	37    	0.7     	2.22045e-16	0.7  	0.7 
65 	40    	0.7     	2.22045e-16	0.7  	0.7 
66 	41    	0.7     	2.22045e-16	0.7  	0.7 
67 	37    	0.7     	2.22045e-16	0.7  	0.7 
68 	38    	0.7     	2.22045e-16	0.7  	0.7 
69 	40    	0.7044  	0.0308     	0.7  	0.92
70 	34    	0.7044  	0.0308     	0.7  	0.92
71 	36    	0.7088  	0.043111   	0.7  	0.92
72 	36    	0.722   	0.066      	0.7  	0.92
73 	42    	0.7264  	0.0714915  	0.7  	0.92
74 	38    	0.7484  	0.0911342  	0.7  	0.92
75 	38    	0.7792  	0.1056     	0.7  	0.92
76 	39    	0.8056  	0.109912   	0.7  	0.92
77 	39    	0.832   	0.107778   	0.7  	0.92
78 	42    	0.8408  	0.1056     	0.7  	0.92
79 	30    	0.8628  	0.0964995  	0.7  	0.92
80 	34    	0.8804  	0.0845212  	0.7  	0.92
81 	37    	0.8848  	0.0806533  	0.7  	0.92
82 	35    	0.898   	0.066      	0.7  	0.92
83 	34    	0.9068  	0.0522471  	0.7  	0.92
84 	39    	0.9068  	0.0522471  	0.7  	0.92
85 	42    	0.9068  	0.0522471  	0.7  	0.92
86 	44    	0.9068  	0.0522471  	0.7  	0.92
87 	39    	0.9112  	0.043111   	0.7  	0.92
88 	34    	0.9112  	0.043111   	0.7  	0.92
89 	36    	0.9112  	0.043111   	0.7  	0.92
90 	40    	0.9112  	0.043111   	0.7  	0.92
91 	38    	0.9112  	0.043111   	0.7  	0.92
92 	42    	0.9156  	0.0308     	0.7  	0.92
93 	40    	0.92    	1.11022e-16	0.92 	0.92
94 	40    	0.92    	1.11022e-16	0.92 	0.92
95 	40    	0.92    	1.11022e-16	0.92 	0.92
96 	39    	0.92    	1.11022e-16	0.92 	0.92
97 	38    	0.92    	1.11022e-16	0.92 	0.92
98 	34    	0.92    	1.11022e-16	0.92 	0.92
99 	38    	0.92    	1.11022e-16	0.92 	0.92
100	39    	0.92    	1.11022e-16	0.92 	0.92
101	40    	0.92    	1.11022e-16	0.92 	0.92
102	36    	0.92    	1.11022e-16	0.92 	0.92
103	40    	0.92    	1.11022e-16	0.92 	0.92
104	36    	0.92    	1.11022e-16	0.92 	0.92
105	44    	0.92    	1.11022e-16	0.92 	0.92
106	35    	0.92    	1.11022e-16	0.92 	0.92
107	39    	0.92    	1.11022e-16	0.92 	0.92
108	40    	0.92    	1.11022e-16	0.92 	0.92
109	34    	0.92    	1.11022e-16	0.92 	0.92
110	42    	0.92    	1.11022e-16	0.92 	0.92
111	35    	0.92    	1.11022e-16	0.92 	0.92
112	37    	0.92    	1.11022e-16	0.92 	0.92
113	39    	0.92    	1.11022e-16	0.92 	0.92
114	40    	0.92    	1.11022e-16	0.92 	0.92
115	40    	0.92    	1.11022e-16	0.92 	0.92
116	36    	0.92    	1.11022e-16	0.92 	0.92
117	26    	0.92    	1.11022e-16	0.92 	0.92
118	41    	0.92    	1.11022e-16	0.92 	0.92
119	39    	0.9216  	0.0112     	0.92 	1   
120	38    	0.922   	0.0114891  	0.92 	1   
121	35    	0.9224  	0.0117576  	0.92 	1   
122	42    	0.9228  	0.0120067  	0.92 	1   
123	42    	0.9248  	0.0162776  	0.92 	1   
124	31    	0.9268  	0.0167857  	0.92 	1   
125	41    	0.9296  	0.0170833  	0.92 	1   
126	38    	0.934   	0.0192873  	0.92 	1   
127	38    	0.938   	0.0204939  	0.92 	1   
128	33    	0.946   	0.0227156  	0.92 	1   
129	39    	0.9528  	0.0273525  	0.92 	1   
130	35    	0.9612  	0.0295053  	0.92 	1   
131	32    	0.9676  	0.0304342  	0.92 	1   
132	32    	0.98    	0.0271293  	0.94 	1   
133	35    	0.986   	0.0240832  	0.94 	1   
134	41    	0.988   	0.0229783  	0.94 	1   
135	37    	0.9908  	0.0200838  	0.94 	1   
136	40    	0.9928  	0.0182253  	0.94 	1   
137	36    	0.9952  	0.0147296  	0.94 	1   
138	37    	0.9968  	0.0108517  	0.96 	1   
139	38    	0.9976  	0.00949947 	0.96 	1   
140	39    	0.9976  	0.00949947 	0.96 	1   
141	35    	0.9984  	0.00783837 	0.96 	1   
142	38    	0.9992  	0.0056     	0.96 	1   
143	37    	1       	0          	1    	1   
144	35    	1       	0          	1    	1   
145	32    	1       	0          	1    	1   
146	35    	1       	0          	1    	1   
147	40    	1       	0          	1    	1   
148	43    	1       	0          	1    	1   
149	38    	1       	0          	1    	1   
150	37    	1       	0          	1    	1   
151	37    	1       	0          	1    	1   
152	36    	1       	0          	1    	1   
153	41    	1       	0          	1    	1   
154	41    	1       	0          	1    	1   
155	39    	1       	0          	1    	1   
156	40    	1       	0          	1    	1   
157	33    	1       	0          	1    	1   
158	37    	1       	0          	1    	1   
159	35    	1       	0          	1    	1   
160	38    	1       	0          	1    	1   
161	37    	1       	0          	1    	1   
162	33    	1       	0          	1    	1   
163	30    	1       	0          	1    	1   
164	37    	1       	0          	1    	1   
165	39    	1       	0          	1    	1   
166	39    	1       	0          	1    	1   
167	34    	1       	0          	1    	1   
168	38    	1       	0          	1    	1   
169	39    	1       	0          	1    	1   
170	31    	1       	0          	1    	1   
171	40    	1       	0          	1    	1   
172	35    	1       	0          	1    	1   
173	26    	1       	0          	1    	1   
174	43    	1       	0          	1    	1   
175	37    	1       	0          	1    	1   
176	37    	1       	0          	1    	1   
177	31    	1       	0          	1    	1   
178	38    	1       	0          	1    	1   
179	38    	1       	0          	1    	1   
180	33    	1       	0          	1    	1   
181	38    	1       	0          	1    	1   
182	37    	1       	0          	1    	1   
183	36    	1       	0          	1    	1   
184	39    	1       	0          	1    	1   
185	36    	1       	0          	1    	1   
186	37    	1       	0          	1    	1   
187	36    	1       	0          	1    	1   
188	43    	1       	0          	1    	1   
189	38    	1       	0          	1    	1   
190	39    	1       	0          	1    	1   
191	39    	1       	0          	1    	1   
192	37    	1       	0          	1    	1   
193	35    	1       	0          	1    	1   
194	39    	1       	0          	1    	1   
195	38    	1       	0          	1    	1   
196	42    	1       	0          	1    	1   
197	37    	1       	0          	1    	1   
198	41    	1       	0          	1    	1   
199	39    	1       	0          	1    	1   
200	33    	1       	0          	1    	1   
[1211, 17516, 14768, 27778, 34988, 8934, 30681, 15502, 5063, 2511, 2038, 942, 12111, 28116, 24814, 36884, 228, 24441, 21898, 5434, 12696, 19253, 33968, 36541, 5902, 18588, 7273, 27399, 26176, 24575, 19896, 24162, 31305, 35885, 18926, 29056, 1576, 37268, 13293, 28560, 39618, 31511, 22267, 14680, 38416, 32344, 33572, 32342, 9085, 37759, 3217, 23387, 20889, 584, 32743, 16858, 13336, 12474, 35941, 16605, 26694, 33578, 10289, 15818, 29059, 26764, 37248, 32521, 31248, 15291, 21537, 27154, 16979, 14166, 23842, 28589, 7, 20616, 7831, 9751, 15555, 19304, 18800, 15393, 23217, 32911, 19220, 29323, 36627, 32992, 33837, 5726, 28715, 38221, 30397, 24712, 29768, 26654, 10161, 35516]
if _in_2 < 3.0:
    out=4
    
else:
    if _in_2 > 3.0:
        out=3
        
    else:
        if _in_1 < 3.0:
            if _in_1 < 3.0:
                out=1
                
            else:
                if _in_0 > 4.0:
                    out=4
                    
                else:
                    if _in_0 > 0.0:
                        out=1
                        
                    else:
                        out=4
                        
                    
                
            
        else:
            out=0
            
        
    
best_fitness: 1.0